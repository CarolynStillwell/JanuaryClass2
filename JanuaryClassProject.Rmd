---
title: "08_project"
author: "CarolynStillwell"
date: "January 21, 2016"
output: html_document
---

**Executive Summary**

Using the Weight Lifting Exercise Dataset from http://groupware.les.inf.puc-rio.br/har this report attempts to predict if a particular exercise was performed correctly based on data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. Using a model generated by the random forest method resulted in a 0.9721 out-of-sample error rate.

**Model Building**

Data was downloaded and split into training and test sets.

```{r downloadandsplit, eval=FALSE}
sourcetesting = read.csv("/StillwellDesign/class/08_machinelearning/pml-testing.csv")
training = read.csv("/StillwellDesign/class/08_machinelearning/pml-training.csv")
inTrain<-createDataPartition(y=training$classe, p=.75, list=FALSE)
trg<-training[inTrain,]
testing<-training[-inTrain,]
```

Preprocessing of the data included removing variables that contained no useful information (e.g., user_name, time and record number) and checking for predictors with near zero variance and removing them:
```{r preprocessing, eval=FALSE}
trg2<-trg[,-c(1,2,3,4,5) ]
nsv<-nearZeroVar(trg2)
trg3 <- trg2[, -nsv]
```

NAs were handled using the knnImpute method:
```{r knnImputing, eval=FALSE}
preObj<-preProcess(trg3[, -97], method="knnImpute")
set.seed(344)
noNAdf<-predict(preObj, trg3[, -97])
trg4<-data.frame(noNAdf, classe=trg3$classe)
```

Then highly correlated predictors were identified and removed:
```{r correlatedpredictors, eval=FALSE}
correlationMatrix <- cor(trg4[,-97])
highlyCorDescr <- findCorrelation(correlationMatrix, cutoff = .75)
trg5 <- trg4[,-highlyCorDescr]
```

Finally PCA was performed and three types of models were tested:
```{r PCAandmodels, eval=FALSE}
modelFit2<-train(trg5$classe~., method="rf", preProcess="pca", data=trg5) 
modelFit2rpart<-train(trg5$classe~., method="rpart", preProcess="pca", data=trg5) 
modelFit2gbm<-train(trg5$classe~., method="gbm", preProcess="pca", data=trg5, verbose=FALSE) 
```

**Cross Validation**

Using the cross validation built into the caret package, the following in-sample accuracy rates were observed:

-- Random Forest (rf): 0.9577010

-- CART (rpart): 0.2851409

-- Stochastic Gradient Boosting (gbm): 0.8040671

And therefore, the random forest model was chosen.

**Expected Out of Sample Error**

Applying this model to the test set, the expected out of sample error is 0.9721 








